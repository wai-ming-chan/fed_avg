{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmKLmNJ0iojuZDviASViXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wai-ming-chan/fed_avg/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic classifier with TensorFlow"
      ],
      "metadata": {
        "id": "bJ_7F_0TjHae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This a series of three tutorials you are in the first one: \n",
        "* [Basic Classifier](https://github.com/coMindOrg/federated-averaging-tutorials/blob/master/Basic%20Classifier.ipynb)\n",
        "* [Basic Distributed Classifier](https://github.com/coMindOrg/federated-averaging-tutorials/blob/master/Basic%20Distributed%20Classifier.ipynb)\n",
        "* [Basic Federated Classifier](https://github.com/coMindOrg/federated-averaging-tutorials/blob/master/Basic%20Federated%20Classifier.ipynb)\n",
        "\n",
        "## What is TensorFlow?\n",
        "\n",
        "TensorFlowâ„¢ is an open source library developed by Google, for high performance numerical computation which has become mainstream within the Deep Learning community. The basic architecture of Tensorflow could be summarized as follows: \n",
        "\n",
        "- Operations are defined (layers of the neural network, sums, multiplications, optimizers ...) as nodes of a graph. \n",
        "\n",
        "- The data is in the form of a tensor. These tensors go through the nodes of the graph, where the defined operations are executed on them (hence the name TensorFlow). \n",
        "\n",
        "- Once the graph and the input tensors have been defined, the entire process described above is executed in a Session.\n",
        "\n",
        "If you would like to get a better idea of how TensorFlow works, we highly reccomed you to read the following article:\n",
        "\n",
        "<a href=\"https://medium.com/@camrongodbout/tensorflow-in-a-nutshell-part-one-basics-3f4403709c9d\">TensorFlow in a nutshell</a>\n",
        "\n",
        "You could also refer to the <a href=\"https://www.tensorflow.org\">official TensorFlow web page</a> for more information, tutorials and instalation guides.\n",
        "\n",
        "This basic classifier tutorial is based on the official TensorFlow tutorial, we have added some additional concepts such as the Datasets API and the Monitored Training Session. This is because we will need those concepts in the more advanced tutorials and we hope showing them here will make the series easier to follow."
      ],
      "metadata": {
        "id": "nm4Dteb0jIXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why only TensorFlow and not keras?\n",
        "\n",
        "TensorFlow incorporates a high level module called keras. It simplifies the usage a TensorFlow to a great extent.\n",
        "\n",
        "These tutorials could also use Keras, but native TensorFlow is more transparent allowing us to demonstrate more easily all the steps and decisions that are taken in the creation of the graph. We will only use Keras to import the data and define the cost function for convenience."
      ],
      "metadata": {
        "id": "j8wdX8lEjLqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First step: import libraries\n",
        "\n",
        "The first one to be imported will be tensorflow, which by agreement is usually given the abbreviated name of tf.\n",
        "\n",
        "Although we really do not need to do to import keras (we could use it from tf.keras) we will also import it separately for convenience.\n",
        "\n",
        "Finally, three traditional basic Python libraries: numpy, matplotlib and time.\n",
        "\n",
        "In the next cell, we also define some basic constant variables for our algorithm. The number of epochs to train and the size of the batches we are going to use for trainning."
      ],
      "metadata": {
        "id": "Q3MeobkvjUSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time"
      ],
      "metadata": {
        "id": "-9xHkZQnjy1B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "iCtT3oiGj7dw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and normalize the data\n",
        "\n",
        "We are going to work with a database called fashion mnist kindly put together by Zalando to substitute the more traditional handwritten digit database. It contains photographs consisting of 28x28 pixels in black and white of 10 different types of clothing. The features on which we will train our model will be the values of each pixel, ranging from 0 to 255.\n",
        "\n",
        "After loading we will divide these values by 255 so that they are normalized between 0 and 1.\n",
        "\n",
        "We have also added a list with the names of the different types of clothing, so that we can visualize the images with their names later on."
      ],
      "metadata": {
        "id": "22NH0HTFj9jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "print('Data loaded')\n",
        "print('Local dataset size: {}'.format(train_images.shape[0]))\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjqVoRNWj_26",
        "outputId": "42b174b8-b6a5-4fd9-9531-4437c6bc453f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Data loaded\n",
            "Local dataset size: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Step\n",
        "\n",
        "Next we create a global step for the optimizer. This is a variable that increases every time the parameters of the model are updated. It is not necessary to create it always in TensorFlow, and it could also be created as a normal variable. However, by creating it through this function we guarantee that any other function that requires the global step will find it through its standardized name (a name that the variable carries below, its context or name scope). In addition, the function checks if a global step already exists, and it associates it with this variable instead of creating a new one."
      ],
      "metadata": {
        "id": "YMo5CZ9YkBd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# global_step = tf.train.get_or_create_global_step()\n",
        "# global_step = tf.training_util.get_or_create_global_step()\n",
        "global_step = tf.compat.v1.train.get_or_create_global_step()"
      ],
      "metadata": {
        "id": "cF7EL3-nkEV4"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}
